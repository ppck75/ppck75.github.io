# 데이터사이언스 논문 리뷰 소모임_20261009
## Computational Grounded Theory: A Methodological Framework_Nelson (2020)
### 경희대학교 전혁식 교수님


**Computational Science 또는 Data Science 관련 논문을 리뷰하는 소모임에서 토론한 내용과 저의 생각을 자유롭게 정리한 글입니다.**

Laura K. Nelson의 Computational Grounded Theory:A Methodological Framework(2020) Article을 리뷰하였습니다.

**논문 정리 게시글 바로가기 -> [Computational Grounded Theory:A Methodological Framework(2020) 논문정리](https://ppck75.github.io/weniv_blog/?post=%5B20260107%5D_%5BNelson_2020_Computational+Grounded+Theory+A+Methodological+Framework%5D_%5BData+Science+Journal+Review%5D_%5B%EB%8D%B0%EC%8B%B8%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B01.jpg%5D_%5BDS+%EB%B0%A9%EB%B2%95%EB%A1%A0+Article%5D_%5B%5D.md)

---
## 토론 질문

### STM은 R에서 제공한다. 파이썬에서는 이를 구현 할 수 있나?

> STM은 R에서 제공하는 패키지이다! 교수님께서는 **BERTopic**을 주로 사용하신다.
> BERTopic(버트토픽)은 BERT 기반 문장 임베딩 + 군집화 + 단어 중요도 추출을 결합한 의미 중심 토픽 모델링 방법이다. 이는 단어 빈도가 아니라 문서의 의미로 토픽을 만드는 모델이다.

    기존 토픽 모델링(LDA)는 단어 동시 등장 확률, 단어 빈도 패턴을 중심으로 토픽을 만든다. 이는, 짧은 텍스트, 은유적 표현, 담론적 의미에 약하다. 

    하지만, BERTopic은 문서를 문장 벡터(의미 벡터)로 바꾼 뒤, 의미가 비슷한 문서들을 묶어 토픽을 형성한다 

**BERTopic의 전체 구조**

① 문서 → 문장 임베딩(임베딩이란 텍스트를 컴퓨터가 계산할 수 있는 숫자 벡터로 바꿔서 의미가 있는 것끼리 가깝게 놓게 만드는 표현 방식이다)

- BERT 계열 모델로 각 문서를 벡터화

- “단어”가 아니라 문서의 의미를 수치로 표현

    단어 임베딩은 단어하나가 벡터 하나. 왕과 영왕은 비슷한 위치, 사과는 과일과 비슷한 위치! 문장 임베딩은 문장, 짧은 글 하나가 벡터 하나. 문장 전체의 뜻(문맥)을 요약한 좌표이다. 즉, 단어가 완전히 같지는 않아도 문장의 의미가 비슷해서 벡터가 가까워질 수 있다. 

    즉, BERTopic은 각 문서를 문장 임베딩으로 바꾸고, 임베딩이 서로 가까운 문서들끼리 묶어서 군집화한다. 그 묶음의 대표 단어를 뽑아서 '토픽'을 만든다. 즉, 단어 빈도가 아니라 문서 의미의 거리로 토픽을 만드는 모델링이다. 

② 차원 축소 

- 고차원 벡터를 저차원으로 압축

- 의미 구조는 유지하면서 군집화가 쉬워짐

③ 군집화

- 군집 개수를 자동 결정

- 애매한 문서는 아웃라이어로 제외 가능 → 사회과학 데이터에 매우 중요

④ 토픽 단어 추출 (c-TF-IDF)

- 각 군집(토픽)에서

- 그 토픽에만 특징적인 단어를 계산 → 토픽의 “의미적 이름표

**Co-occurrence Matrix란 무엇인가?**
코어 어커런스 방법은
특정 **핵심 단어(core word)**가
어떤 단어들과 함께 등장하는지를 분석하여,
그 단어가 어떤 의미적·사회적 맥락 속에서 사용되는지를 파악하는 텍스트 분석 방법이다. (단어의 의미는 고정된 정의가 아니라, 함께 쓰이는 단어들의 네트워크 속에서 구성된다.)


> 핵심 키워드들 간의 ‘동시 등장 빈도’를 수치로 나타낸 관계 표이다. 
> 핵심 아이디어: 단어의 의미는 혼자 있지 않고, 항상 다른 단어들과 함께 등장한다.

    예를 들어, 'gay'가 어떤 단어들과 함께 쓰였는가를 보면 그 단어의 사회적 의미를 알 수 있다. 

    과거 gay라는 단어의 코어 어커런스가 happy, cheerful 등 이었다면, 현재에는 lesbian, sexual, rights 등이다. 이를 통해 시간과 공간에 따른 담론의 진화 과정과 구조를 보여줄 수 있다. (시간과 공간에 따라 의미가 달라진 것이다) 이는 사전적 의미의 변화가 아니라, '사회적 사용 의미'의 변화를 분석하는 방법이다. 


### Topic Modeling에서 파라미터 결정에 도움이 되는 다른 방법이 없을까?

> 토픽 모델링에서도 K_means처럼 파라미터 결정에 도움이 되는 기법이 존재한다. 하지만, 절대적으로 맞는 것은 아니다. 즉, 'robust'를 체크하는 방법일뿐 절대적인 가이드라인을 제공하는 것은 아니다.  

> 우리는 종종 이러한 방식이 완전히 객관전인 것이라고 오해하기 쉽다. 항상 우리는 연구자가 언급하지 않은 연구의 '블랙박스'를 열어보아야 한다. 


### 논문에서 step3의 역할
> step3는 본 연구의 데이터 분석 기법 뿐 아니라 다른 방식으로도 확인 받을 수 있나?를 답하기 위한 단계이다. 즉, robust를 체크하기 위한 것이다. 
> 그런데, 한국어 대상 연구에는 step3까지 나아가는 경우가 거의 없다. 한국어는 토크나이저 자체가 좋은 것이 없기 때문에 한계가 있다. 이러한 이유로 대부분의 국내 연구는 step2까지 진행된다.  

### 그 외

- Topic Modeling에서도 중요한 것은 '가정'이다. 어떠한 분석 기법을 쓸 때에는 그 분석 기법을 적용할 수 있는지 가정을 살펴보아야 한다. (마치 회귀분석에서 선형성, 등분산성, 잔차의 독립성, 정규성 처럼 가정이 맞아야 사용할 수 있다)

- 이 논문의 셀링 포인트는 투명성, 반복 가능성, 효율성이다.

- 어떤 연구든 완벽한 것은 없지만, 가장 중요한 것은 '나의 데이터가 무엇을 말할 수 있고 또 없는지 그리고 그러한 것을 극복하기 위해 어떤 시도를 했는지'를 설명하는 것이다. 이것을 설명하는 것이 훌륭한 데이터사이언티스트이다. 

---


## References

Nelson, L. K. (2020). *Computational grounded theory: A methodological framework*.  
*Sociological Methods & Research, 49*(1), 3–42.  
https://doi.org/10.1177/0049124117729703

